#!/usr/bin/env python3
import requests
import json
import sys

from archive.code_runner import run_code

MAX_RETRIES = 3


def generate_extraction_code(html):
    """
    Simulate a call to gpt-4o to generate extraction code based on the provided HTML.
    Returns a string of Python code that extracts structured data.
    """
    # Example extraction code generated by gpt-4o for tabular data extraction
    code = """
import sys
import json
from bs4 import BeautifulSoup

def extract_data(html):
    soup = BeautifulSoup(html, 'html.parser')
    tables = []
    for table in soup.find_all('table'):
        headers = []
        rows = []
        # Check if table has a header row
        header_row = table.find('tr')
        if header_row and header_row.find_all('th'):
            headers = [th.get_text(strip=True) for th in header_row.find_all('th')]
            for row in table.find_all('tr')[1:]:
                cells = [td.get_text(strip=True) for td in row.find_all('td')]
                if cells:
                    # Map headers to cells, if possible
                    row_data = dict(zip(headers, cells))
                    rows.append(row_data)
        else:
            for row in table.find_all('tr'):
                cells = [td.get_text(strip=True) for td in row.find_all('td')]
                if cells:
                    rows.append(cells)
        tables.append({"headers": headers, "rows": rows})
    return {"tables": tables}

if __name__ == "__main__":
    html = sys.stdin.read()
    data = extract_data(html)
    print(json.dumps(data))
"""
    return code


def revise_extraction_code(error_message, previous_code):
    """
    Simulate a call to gpt-4o to revise the extraction code based on the error feedback.
    For demonstration purposes, this function simply appends a comment about the error.
    """
    revised_code = previous_code + f"\n# Revised based on error: {error_message}\n"
    return revised_code


def fetch_html(url):
    """
    Fetch the HTML content of a webpage.
    """
    try:
        response = requests.get(url)
        response.raise_for_status()
        return response.text
    except Exception as e:
        print("Error fetching URL:", e)
        sys.exit(1)


def save_output(data, filename="output.json"):
    """
    Save the extracted structured data to a file.
    """
    try:
        with open(filename, "w") as f:
            json.dump(data, f, indent=2)
        print(f"Extracted data saved to {filename}")
    except Exception as e:
        print("Error saving output:", e)


def main():
    # Hardcoded URL
    url = "https://www.basketball-reference.com/players/j/jamesle01.html"

    # Step 1: Fetch HTML content from the URL
    html = fetch_html(url)

    # Step 2: Generate extraction code using gpt-4o
    extraction_code = generate_extraction_code(html)

    # Step 3: Execute the extraction code in a sandbox using run_code and incorporate feedback loop
    attempt = 0
    while attempt < MAX_RETRIES:
        print(f"Attempt {attempt+1}: executing extraction code...")
        output = run_code(extraction_code, html)
        try:
            # Try to parse the output as JSON to verify correct extraction
            result_data = json.loads(output)
            print("Extraction successful!")
            save_output(result_data)
            break
        except json.JSONDecodeError as e:
            print("Extraction failed; output not valid JSON. Error:", e)
            # Provide feedback to gpt-4o to revise the extraction code
            extraction_code = revise_extraction_code(str(e), extraction_code)
            attempt += 1
    else:
        print("Extraction failed after maximum retries.")
        sys.exit(1)


if __name__ == "__main__":
    main()
